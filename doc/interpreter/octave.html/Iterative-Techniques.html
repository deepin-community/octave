<!DOCTYPE html>
<html>
<!-- Created by GNU Texinfo 7.1, https://www.gnu.org/software/texinfo/ -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Iterative Techniques (GNU Octave (version 9.2.0))</title>

<meta name="description" content="Iterative Techniques (GNU Octave (version 9.2.0))">
<meta name="keywords" content="Iterative Techniques (GNU Octave (version 9.2.0))">
<meta name="resource-type" content="document">
<meta name="distribution" content="global">
<meta name="Generator" content="makeinfo">
<meta name="viewport" content="width=device-width,initial-scale=1">

<link href="index.html" rel="start" title="Top">
<link href="Concept-Index.html" rel="index" title="Concept Index">
<link href="index.html#SEC_Contents" rel="contents" title="Table of Contents">
<link href="Sparse-Matrices.html" rel="up" title="Sparse Matrices">
<link href="Real-Life-Example.html" rel="next" title="Real Life Example">
<link href="Sparse-Linear-Algebra.html" rel="prev" title="Sparse Linear Algebra">
<style type="text/css">
<!--
a.copiable-link {visibility: hidden; text-decoration: none; line-height: 0em}
div.example {margin-left: 3.2em}
span:hover a.copiable-link {visibility: visible}
strong.def-name {font-family: monospace; font-weight: bold; font-size: larger}
ul.mark-bullet {list-style-type: disc}
-->
</style>
<link rel="stylesheet" type="text/css" href="octave.css">


</head>

<body lang="en">
<div class="section-level-extent" id="Iterative-Techniques">
<div class="nav-panel">
<p>
Next: <a href="Real-Life-Example.html" accesskey="n" rel="next">Real Life Example using Sparse Matrices</a>, Previous: <a href="Sparse-Linear-Algebra.html" accesskey="p" rel="prev">Linear Algebra on Sparse Matrices</a>, Up: <a href="Sparse-Matrices.html" accesskey="u" rel="up">Sparse Matrices</a> &nbsp; [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Concept-Index.html" title="Index" rel="index">Index</a>]</p>
</div>
<hr>
<h3 class="section" id="Iterative-Techniques-Applied-to-Sparse-Matrices"><span>22.3 Iterative Techniques Applied to Sparse Matrices<a class="copiable-link" href="#Iterative-Techniques-Applied-to-Sparse-Matrices"> &para;</a></span></h3>

<p>The left division <code class="code">\</code> and right division <code class="code">/</code> operators,
discussed in the previous section, use direct solvers to resolve a
linear equation of the form <code class="code"><var class="var">x</var> = <var class="var">A</var> \ <var class="var">b</var></code> or
<code class="code"><var class="var">x</var> = <var class="var">b</var> / <var class="var">A</var></code>.  Octave also includes a number of
functions to solve sparse linear equations using iterative techniques.
</p>
<a class="anchor" id="XREFpcg"></a><span style="display:block; margin-top:-4.5ex;">&nbsp;</span>


<dl class="first-deftypefn">
<dt class="deftypefn" id="index-pcg"><span class="category-def">: </span><span><code class="def-type"><var class="var">x</var> =</code> <strong class="def-name">pcg</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, <var class="var">tol</var>, <var class="var">maxit</var>, <var class="var">m1</var>, <var class="var">m2</var>, <var class="var">x0</var>, &hellip;)</code><a class="copiable-link" href="#index-pcg"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-pcg-1"><span class="category-def">: </span><span><code class="def-type"><var class="var">x</var> =</code> <strong class="def-name">pcg</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, <var class="var">tol</var>, <var class="var">maxit</var>, <var class="var">M</var>, [], <var class="var">x0</var>, &hellip;)</code><a class="copiable-link" href="#index-pcg-1"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-pcg-2"><span class="category-def">: </span><span><code class="def-type">[<var class="var">x</var>, <var class="var">flag</var>, <var class="var">relres</var>, <var class="var">iter</var>, <var class="var">resvec</var>, <var class="var">eigest</var>] =</code> <strong class="def-name">pcg</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, &hellip;)</code><a class="copiable-link" href="#index-pcg-2"> &para;</a></span></dt>
<dd>
<p>Solve the linear system of equations <code class="code"><var class="var">A</var>&nbsp;*&nbsp;<var class="var">x</var>&nbsp;=&nbsp;<var class="var">b</var></code><!-- /@w -->
by means of the Preconditioned Conjugate Gradient iterative method.
</p>
<p>The input arguments are:
</p>
<ul class="itemize mark-bullet">
<li><var class="var">A</var> is the matrix of the linear system and it must be square.
<var class="var">A</var> can be passed as a matrix, function handle, or inline function
<code class="code">Afcn</code> such that <code class="code">Afcn(x) = A * x</code>.  Additional parameters to
<code class="code">Afcn</code> may be passed after <var class="var">x0</var>.

<p><var class="var">A</var> has to be Hermitian and Positive Definite (HPD).  If
<code class="code">pcg</code> detects <var class="var">A</var> not to be positive definite, a warning is printed
and the <var class="var">flag</var> output is set.
</p>
</li><li><var class="var">b</var> is the right-hand side vector.

</li><li><var class="var">tol</var> is the required relative tolerance for the residual error,
<code class="code"><var class="var">b</var>&nbsp;-&nbsp;<var class="var">A</var>&nbsp;*&nbsp;<var class="var">x</var></code><!-- /@w -->.  The iteration stops if
<code class="code">norm&nbsp;(<var class="var">b</var>&nbsp;-&nbsp;<var class="var">A</var>&nbsp;*&nbsp;<var class="var">x</var>)</code>&nbsp;&le;&nbsp;<code class="code"><var class="var">tol</var>&nbsp;*&nbsp;norm&nbsp;(<var class="var">b</var>)</code><!-- /@w --><!-- /@w -->.
If <var class="var">tol</var> is omitted or empty, then a tolerance of 1e-6 is used.

</li><li><var class="var">maxit</var> is the maximum allowed number of iterations; if <var class="var">maxit</var>
is omitted or empty then a value of 20 is used.

</li><li><var class="var">m</var> is a HPD preconditioning matrix.  For any decomposition
<code class="code"><var class="var">m</var> = <var class="var">p1</var> * <var class="var">p2</var></code> such that
<code class="code">inv&nbsp;(<var class="var">p1</var>)&nbsp;*&nbsp;<var class="var">A</var>&nbsp;*&nbsp;inv&nbsp;(<var class="var">p2</var>)</code><!-- /@w --> is HPD, the
conjugate gradient method is formally applied to the linear system
<code class="code">inv&nbsp;(<var class="var">p1</var>)&nbsp;*&nbsp;<var class="var">A</var>&nbsp;*&nbsp;inv&nbsp;(<var class="var">p2</var>)&nbsp;*&nbsp;<var class="var">y</var>&nbsp;=&nbsp;inv&nbsp;(<var class="var">p1</var>)&nbsp;*&nbsp;<var class="var">b</var></code><!-- /@w -->,
with <code class="code"><var class="var">x</var> = inv (<var class="var">p2</var>) * <var class="var">y</var></code> (split preconditioning).
In practice, at each iteration of the conjugate gradient method a
linear system with matrix <var class="var">m</var> is solved with <code class="code">mldivide</code>.
If a particular factorization
<code class="code"><var class="var">m</var> = <var class="var">m1</var> * <var class="var">m2</var></code> is available (for instance, an
incomplete Cholesky factorization of <var class="var">a</var>), the two matrices
<var class="var">m1</var> and <var class="var">m2</var> can be passed and the relative linear systems
are solved with the <code class="code">mldivide</code> operator.
Note that a proper choice of the preconditioner may dramatically improve
the overall performance of the method.  Instead of matrices <var class="var">m1</var> and
<var class="var">m2</var>, the user may pass two functions which return the results of
applying the inverse of <var class="var">m1</var> and <var class="var">m2</var> to a vector.
If <var class="var">m1</var> is omitted or empty <code class="code">[]</code>, then no preconditioning
is applied.  If no factorization of <var class="var">m</var> is available, <var class="var">m2</var>
can be omitted or left [], and the input variable <var class="var">m1</var> can be
used to pass the preconditioner <var class="var">m</var>.

</li><li><var class="var">x0</var> is the initial guess.  If <var class="var">x0</var> is omitted or empty then the
function sets <var class="var">x0</var> to a zero vector by default.
</li></ul>

<p>The arguments which follow <var class="var">x0</var> are treated as parameters, and passed in
an appropriate manner to any of the functions (<var class="var">A</var> or <var class="var">m1</var> or
<var class="var">m2</var>) that have been given to <code class="code">pcg</code>.
See the examples below for further details.
</p>
<p>The output arguments are:
</p>
<ul class="itemize mark-bullet">
<li><var class="var">x</var> is the computed approximation to the solution of
<code class="code"><var class="var">A</var>&nbsp;*&nbsp;<var class="var">x</var>&nbsp;=&nbsp;<var class="var">b</var></code><!-- /@w -->.  If the algorithm did not converge,
then <var class="var">x</var> is the iteration which has the minimum residual.

</li><li><var class="var">flag</var> reports on the convergence:

<ul class="itemize mark-bullet">
<li>0: The algorithm converged to within the prescribed tolerance.

</li><li>1: The algorithm did not converge and it reached the maximum
number of iterations.

</li><li>2: The preconditioner matrix is singular.

</li><li>3: The algorithm stagnated, i.e., the absolute value of the
difference between the current iteration <var class="var">x</var> and the previous is less
than <code class="code"><var class="var">eps</var> * norm (<var class="var">x</var>,2)</code>.

</li><li>4: The algorithm detects that the input (preconditioned) matrix is not
HPD.
</li></ul>

</li><li><var class="var">relres</var> is the ratio of the final residual to its initial value,
measured in the Euclidean norm.

</li><li><var class="var">iter</var> indicates the iteration of <var class="var">x</var> which it was
computed.  Since the output <var class="var">x</var> corresponds to the minimal
residual solution, the total number of iterations that
the method performed is given by <code class="code">length(resvec) - 1</code>.

</li><li><var class="var">resvec</var> describes the convergence history of the method.
<code class="code"><var class="var">resvec</var> (<var class="var">i</var>, 1)</code> is the Euclidean norm of the residual, and
<code class="code"><var class="var">resvec</var> (<var class="var">i</var>, 2)</code> is the preconditioned residual
norm, after the
(<var class="var">i</var>-1)-th iteration, <code class="code"><var class="var">i</var> = 1, 2, &hellip;, <var class="var">iter</var>+1</code>.
The preconditioned residual norm is defined as
<code class="code"><var class="var">r</var>' * (<var class="var">m</var> \ <var class="var">r</var>)</code> where
<code class="code"><var class="var">r</var> = <var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var></code>, see also the
description of <var class="var">m</var>.  If <var class="var">eigest</var> is not required, only
<code class="code"><var class="var">resvec</var> (:, 1)</code> is returned.

</li><li><var class="var">eigest</var> returns the estimate for the smallest <code class="code"><var class="var">eigest</var>(1)</code>
and largest <code class="code"><var class="var">eigest</var>(2)</code> eigenvalues of the preconditioned matrix
<code class="code"><var class="var">P</var>&nbsp;=&nbsp;<var class="var">m</var>&nbsp;\&nbsp;<var class="var">A</var></code><!-- /@w -->.  In particular, if no
preconditioning is used, the estimates for the extreme eigenvalues of
<var class="var">A</var> are returned.  <code class="code"><var class="var">eigest</var>(1)</code> is an overestimate and
<code class="code"><var class="var">eigest</var>(2)</code> is an underestimate, so that
<code class="code"><var class="var">eigest</var>(2) / <var class="var">eigest</var>(1)</code> is a lower bound for
<code class="code">cond (<var class="var">P</var>, 2)</code>, which nevertheless in the limit should
theoretically be equal to the actual value of the condition number.
</li></ul>


<p>Let us consider a trivial problem with a tridiagonal matrix
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">n = 10;
A = toeplitz (sparse ([1, 1], [1, 2], [2, 1], 1, n));
b = A * ones (n, 1);
M1 = ichol (A); # in this tridiagonal case it corresponds to chol (A)'
M2 = M1';
M = M1 * M2;
Afcn = @(x) A * x;
Mfcn = @(x) M \ x;
M1fcn = @(x) M1 \ x;
M2fcn = @(x) M2 \ x;
</pre></div></div>

<p><small class="sc">EXAMPLE 1:</small> Simplest use of <code class="code">pcg</code>
</p>
<div class="example">
<pre class="example-preformatted">x = pcg (A, b)
</pre></div>

<p><small class="sc">EXAMPLE 2:</small> <code class="code">pcg</code> with a function which computes
<code class="code"><var class="var">A</var> * <var class="var">x</var></code>
</p>
<div class="example">
<pre class="example-preformatted">x = pcg (Afcn, b)
</pre></div>

<p><small class="sc">EXAMPLE 3:</small> <code class="code">pcg</code> with a preconditioner matrix <var class="var">M</var>
</p>
<div class="example">
<pre class="example-preformatted">x = pcg (A, b, 1e-06, 100, M)
</pre></div>

<p><small class="sc">EXAMPLE 4:</small> <code class="code">pcg</code> with a function as preconditioner
</p>
<div class="example">
<pre class="example-preformatted">x = pcg (Afcn, b, 1e-6, 100, Mfcn)
</pre></div>

<p><small class="sc">EXAMPLE 5:</small> <code class="code">pcg</code> with preconditioner matrices <var class="var">M1</var>
and <var class="var">M2</var>
</p>
<div class="example">
<pre class="example-preformatted">x = pcg (A, b, 1e-6, 100, M1, M2)
</pre></div>

<p><small class="sc">EXAMPLE 6:</small> <code class="code">pcg</code> with functions as preconditioners
</p>
<div class="example">
<pre class="example-preformatted">x = pcg (Afcn, b, 1e-6, 100, M1fcn, M2fcn)
</pre></div>

<p><small class="sc">EXAMPLE 7:</small> <code class="code">pcg</code> with as input a function requiring an argument
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">  function y = Ap (A, x, p) # compute A^p * x
     y = x;
     for i = 1:p
       y = A * y;
     endfor
  endfunction
Apfcn = @(x, p) Ap (A, x, p);
x = pcg (Apfcn, b, [], [], [], [], [], 2);
</pre></div></div>

<p><small class="sc">EXAMPLE 8:</small> explicit example to show that <code class="code">pcg</code> uses a
split preconditioner
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">M1 = ichol (A + 0.1 * eye (n)); # factorization of A perturbed
M2 = M1';
M = M1 * M2;

## reference solution computed by pcg after two iterations
[x_ref, fl] = pcg (A, b, [], 2, M)

## split preconditioning
[y, fl] = pcg ((M1 \ A) / M2, M1 \ b, [], 2)
x = M2 \ y # compare x and x_ref

</pre></div></div>

<p>References:
</p>
<ol class="enumerate">
<li> C.T. Kelley, <cite class="cite">Iterative Methods for Linear and Nonlinear Equations</cite>,
SIAM, 1995. (the base PCG algorithm)

</li><li> Y. Saad, <cite class="cite">Iterative Methods for Sparse Linear Systems</cite>,
PWS 1996. (condition number estimate from PCG)
Revised version of this book is available online at
<a class="url" href="https://www-users.cs.umn.edu/~saad/books.html">https://www-users.cs.umn.edu/~saad/books.html</a>
</li></ol>


<p><strong class="strong">See also:</strong> <a class="ref" href="Creating-Sparse-Matrices.html#XREFsparse">sparse</a>, <a class="ref" href="#XREFpcr">pcr</a>, <a class="ref" href="Specialized-Solvers.html#XREFgmres">gmres</a>, <a class="ref" href="Specialized-Solvers.html#XREFbicg">bicg</a>, <a class="ref" href="Specialized-Solvers.html#XREFbicgstab">bicgstab</a>, <a class="ref" href="Specialized-Solvers.html#XREFcgs">cgs</a>.
</p></dd></dl>


<a class="anchor" id="XREFpcr"></a><span style="display:block; margin-top:-4.5ex;">&nbsp;</span>


<dl class="first-deftypefn">
<dt class="deftypefn" id="index-pcr"><span class="category-def">: </span><span><code class="def-type"><var class="var">x</var> =</code> <strong class="def-name">pcr</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">b</var>, <var class="var">tol</var>, <var class="var">maxit</var>, <var class="var">m</var>, <var class="var">x0</var>, &hellip;)</code><a class="copiable-link" href="#index-pcr"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-pcr-1"><span class="category-def">: </span><span><code class="def-type">[<var class="var">x</var>, <var class="var">flag</var>, <var class="var">relres</var>, <var class="var">iter</var>, <var class="var">resvec</var>] =</code> <strong class="def-name">pcr</strong> <code class="def-code-arguments">(&hellip;)</code><a class="copiable-link" href="#index-pcr-1"> &para;</a></span></dt>
<dd>
<p>Solve the linear system of equations <code class="code"><var class="var">A</var> * <var class="var">x</var> = <var class="var">b</var></code> by
means of the Preconditioned Conjugate Residuals iterative method.
</p>
<p>The input arguments are
</p>
<ul class="itemize mark-bullet">
<li><var class="var">A</var> can be either a square (preferably sparse) matrix or a function
handle, inline function or string containing the name of a function which
computes <code class="code"><var class="var">A</var> * <var class="var">x</var></code>.  In principle <var class="var">A</var> should be
symmetric and non-singular; if <code class="code">pcr</code> finds <var class="var">A</var> to be numerically
singular, you will get a warning message and the <var class="var">flag</var> output
parameter will be set.

</li><li><var class="var">b</var> is the right hand side vector.

</li><li><var class="var">tol</var> is the required relative tolerance for the residual error,
<code class="code"><var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var></code>.  The iteration stops if
<code class="code">norm (<var class="var">b</var> - <var class="var">A</var> * <var class="var">x</var>) &lt;=
<var class="var">tol</var> * norm (<var class="var">b</var> - <var class="var">A</var> * <var class="var">x0</var>)</code>.
If <var class="var">tol</var> is empty or is omitted, the function sets
<code class="code"><var class="var">tol</var> = 1e-6</code> by default.

</li><li><var class="var">maxit</var> is the maximum allowable number of iterations; if <code class="code">[]</code> is
supplied for <var class="var">maxit</var>, or <code class="code">pcr</code> has less arguments, a default
value equal to 20 is used.

</li><li><var class="var">m</var> is the (left) preconditioning matrix, so that the iteration is
(theoretically) equivalent to solving by
<code class="code">pcr</code> <code class="code"><var class="var">P</var> * <var class="var">x</var> = <var class="var">m</var> \ <var class="var">b</var></code>, with
<code class="code"><var class="var">P</var> = <var class="var">m</var> \ <var class="var">A</var></code>.  Note that a proper choice of the
preconditioner may dramatically improve the overall performance of the
method.  Instead of matrix <var class="var">m</var>, the user may pass a function which
returns the results of applying the inverse of <var class="var">m</var> to a vector
(usually this is the preferred way of using the preconditioner).  If
<code class="code">[]</code> is supplied for <var class="var">m</var>, or <var class="var">m</var> is omitted, no
preconditioning is applied.

</li><li><var class="var">x0</var> is the initial guess.  If <var class="var">x0</var> is empty or omitted, the
function sets <var class="var">x0</var> to a zero vector by default.
</li></ul>

<p>The arguments which follow <var class="var">x0</var> are treated as parameters, and passed
in a proper way to any of the functions (<var class="var">A</var> or <var class="var">m</var>) which are
passed to <code class="code">pcr</code>.  See the examples below for further details.
</p>
<p>The output arguments are
</p>
<ul class="itemize mark-bullet">
<li><var class="var">x</var> is the computed approximation to the solution of
<code class="code"><var class="var">A</var> * <var class="var">x</var> = <var class="var">b</var></code>.

</li><li><var class="var">flag</var> reports on the convergence.  <code class="code"><var class="var">flag</var> = 0</code> means the
solution converged and the tolerance criterion given by <var class="var">tol</var> is
satisfied.  <code class="code"><var class="var">flag</var> = 1</code> means that the <var class="var">maxit</var> limit for the
iteration count was reached.  <code class="code"><var class="var">flag</var> = 3</code> reports a <code class="code">pcr</code>
breakdown, see [1] for details.

</li><li><var class="var">relres</var> is the ratio of the final residual to its initial value,
measured in the Euclidean norm.

</li><li><var class="var">iter</var> is the actual number of iterations performed.

</li><li><var class="var">resvec</var> describes the convergence history of the method, so that
<code class="code"><var class="var">resvec</var> (i)</code> contains the Euclidean norms of the residual after
the (<var class="var">i</var>-1)-th iteration, <code class="code"><var class="var">i</var> = 1,2, &hellip;, <var class="var">iter</var>+1</code>.
</li></ul>

<p>Let us consider a trivial problem with a diagonal matrix (we exploit the
sparsity of A)
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">n = 10;
A = sparse (diag (1:n));
b = rand (N, 1);
</pre></div></div>

<p><small class="sc">EXAMPLE 1:</small> Simplest use of <code class="code">pcr</code>
</p>
<div class="example">
<pre class="example-preformatted">x = pcr (A, b)
</pre></div>

<p><small class="sc">EXAMPLE 2:</small> <code class="code">pcr</code> with a function which computes
<code class="code"><var class="var">A</var> * <var class="var">x</var></code>.
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">function y = apply_a (x)
  y = [1:10]' .* x;
endfunction

x = pcr (&quot;apply_a&quot;, b)
</pre></div></div>

<p><small class="sc">EXAMPLE 3:</small>  Preconditioned iteration, with full diagnostics.  The
preconditioner (quite strange, because even the original matrix
<var class="var">A</var> is trivial) is defined as a function
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">function y = apply_m (x)
  k = floor (length (x) - 2);
  y = x;
  y(1:k) = x(1:k) ./ [1:k]';
endfunction

[x, flag, relres, iter, resvec] = ...
                   pcr (A, b, [], [], &quot;apply_m&quot;)
semilogy ([1:iter+1], resvec);
</pre></div></div>

<p><small class="sc">EXAMPLE 4:</small> Finally, a preconditioner which depends on a
parameter <var class="var">k</var>.
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">function y = apply_m (x, varargin)
  k = varargin{1};
  y = x;
  y(1:k) = x(1:k) ./ [1:k]';
endfunction

[x, flag, relres, iter, resvec] = ...
                   pcr (A, b, [], [], &quot;apply_m&quot;', [], 3)
</pre></div></div>

<p>Reference:
</p>
<p>W. Hackbusch, <cite class="cite">Iterative Solution of Large Sparse
Systems of Equations</cite>, section 9.5.4; Springer, 1994
</p>

<p><strong class="strong">See also:</strong> <a class="ref" href="Creating-Sparse-Matrices.html#XREFsparse">sparse</a>, <a class="ref" href="#XREFpcg">pcg</a>.
</p></dd></dl>


<p>The speed with which an iterative solver converges to a solution can be
accelerated with the use of a pre-conditioning matrix <var class="var">M</var>.  In this
case the linear equation <code class="code"><var class="var">M</var>^-1 * <var class="var">x</var> = <var class="var">M</var>^-1 *
<var class="var">A</var> \ <var class="var">b</var></code> is solved instead.  Typical pre-conditioning matrices
are partial factorizations of the original matrix.
</p>
<a class="anchor" id="XREFichol"></a><span style="display:block; margin-top:-4.5ex;">&nbsp;</span>


<dl class="first-deftypefn">
<dt class="deftypefn" id="index-ichol"><span class="category-def">: </span><span><code class="def-type"><var class="var">L</var> =</code> <strong class="def-name">ichol</strong> <code class="def-code-arguments">(<var class="var">A</var>)</code><a class="copiable-link" href="#index-ichol"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-ichol-1"><span class="category-def">: </span><span><code class="def-type"><var class="var">L</var> =</code> <strong class="def-name">ichol</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">opts</var>)</code><a class="copiable-link" href="#index-ichol-1"> &para;</a></span></dt>
<dd>
<p>Compute the incomplete Cholesky factorization of the sparse square matrix
<var class="var">A</var>.
</p>
<p>By default, <code class="code">ichol</code> uses only the lower triangle of <var class="var">A</var> and
produces a lower triangular factor <var class="var">L</var> such that <code class="code">L*L'</code>
approximates <var class="var">A</var>.
</p>
<p>The factor given by this routine may be useful as a preconditioner for a
system of linear equations being solved by iterative methods such as
PCG (Preconditioned Conjugate Gradient).
</p>
<p>The factorization may be modified by passing options in a structure
<var class="var">opts</var>.  The option name is a field of the structure and the setting
is the value of field.  Names and specifiers are case sensitive.
</p>
<dl class="table">
<dt>type</dt>
<dd><p>Type of factorization.
</p>
<dl class="table">
<dt><code class="code">&quot;nofill&quot;</code> (default)</dt>
<dd><p>Incomplete Cholesky factorization with no fill-in (IC(0)).
</p>
</dd>
<dt><code class="code">&quot;ict&quot;</code></dt>
<dd><p>Incomplete Cholesky factorization with threshold dropping (ICT).
</p></dd>
</dl>

</dd>
<dt>diagcomp</dt>
<dd><p>A non-negative scalar <var class="var">alpha</var> for incomplete Cholesky factorization of
<code class="code"><var class="var">A</var> + <var class="var">alpha</var> * diag (diag (<var class="var">A</var>))</code> instead of <var class="var">A</var>.
This can be useful when <var class="var">A</var> is not positive definite.  The default value
is 0.
</p>
</dd>
<dt>droptol</dt>
<dd><p>A non-negative scalar specifying the drop tolerance for factorization if
performing ICT.  The default value is 0 which produces the
complete Cholesky factorization.
</p>
<p>Non-diagonal entries of <var class="var">L</var> are set to 0 unless
</p>
<p><code class="code">abs (<var class="var">L</var>(i,j)) &gt;= droptol * norm (<var class="var">A</var>(j:end, j), 1)</code>.
</p>
</dd>
<dt>michol</dt>
<dd><p>Modified incomplete Cholesky factorization:
</p>
<dl class="table">
<dt><code class="code">&quot;off&quot;</code> (default)</dt>
<dd><p>Row and column sums are not necessarily preserved.
</p>
</dd>
<dt><code class="code">&quot;on&quot;</code></dt>
<dd><p>The diagonal of <var class="var">L</var> is modified so that row (and column) sums are
preserved even when elements have been dropped during the factorization.
The relationship preserved is: <code class="code"><var class="var">A</var> * e = <var class="var">L</var> * <var class="var">L</var>' * e</code>,
where e is a vector of ones.
</p></dd>
</dl>

</dd>
<dt>shape</dt>
<dd>
<dl class="table">
<dt><code class="code">&quot;lower&quot;</code> (default)</dt>
<dd><p>Use only the lower triangle of <var class="var">A</var> and return a lower triangular factor
<var class="var">L</var> such that <code class="code">L*L'</code> approximates <var class="var">A</var>.
</p>
</dd>
<dt><code class="code">&quot;upper&quot;</code></dt>
<dd><p>Use only the upper triangle of <var class="var">A</var> and return an upper triangular factor
<var class="var">U</var> such that <code class="code">U'*U</code> approximates <var class="var">A</var>.
</p></dd>
</dl>
</dd>
</dl>

<p>EXAMPLES
</p>
<p>The following problem demonstrates how to factorize a sample symmetric
positive definite matrix with the full Cholesky decomposition and with the
incomplete one.
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">A = [ 0.37, -0.05,  -0.05,  -0.07;
     -0.05,  0.116,  0.0,   -0.05;
     -0.05,  0.0,    0.116, -0.05;
     -0.07, -0.05,  -0.05,   0.202];
A = sparse (A);
nnz (tril (A))
ans =  9
L = chol (A, &quot;lower&quot;);
nnz (L)
ans =  10
norm (A - L * L', &quot;fro&quot;) / norm (A, &quot;fro&quot;)
ans =  1.1993e-16
opts.type = &quot;nofill&quot;;
L = ichol (A, opts);
nnz (L)
ans =  9
norm (A - L * L', &quot;fro&quot;) / norm (A, &quot;fro&quot;)
ans =  0.019736
</pre></div></div>

<p>Another example for decomposition is a finite difference matrix used to
solve a boundary value problem on the unit square.
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">nx = 400; ny = 200;
hx = 1 / (nx + 1); hy = 1 / (ny + 1);
Dxx = spdiags ([ones(nx, 1), -2*ones(nx, 1), ones(nx, 1)],
               [-1 0 1 ], nx, nx) / (hx ^ 2);
Dyy = spdiags ([ones(ny, 1), -2*ones(ny, 1), ones(ny, 1)],
               [-1 0 1 ], ny, ny) / (hy ^ 2);
A = -kron (Dxx, speye (ny)) - kron (speye (nx), Dyy);
nnz (tril (A))
ans =  239400
opts.type = &quot;nofill&quot;;
L = ichol (A, opts);
nnz (tril (A))
ans =  239400
norm (A - L * L', &quot;fro&quot;) / norm (A, &quot;fro&quot;)
ans =  0.062327
</pre></div></div>

<p>References for implemented algorithms:
</p>
<p>[1] Y. Saad. &quot;Preconditioning Techniques.&quot; <cite class="cite">Iterative
Methods for Sparse Linear Systems</cite>, PWS Publishing Company, 1996.
</p>
<p>[2] M. Jones, P. Plassmann: <cite class="cite">An Improved Incomplete
Cholesky Factorization</cite>, 1992.
</p>
<p><strong class="strong">See also:</strong> <a class="ref" href="Matrix-Factorizations.html#XREFchol">chol</a>, <a class="ref" href="#XREFilu">ilu</a>, <a class="ref" href="#XREFpcg">pcg</a>.
</p></dd></dl>


<a class="anchor" id="XREFilu"></a><span style="display:block; margin-top:-4.5ex;">&nbsp;</span>


<dl class="first-deftypefn">
<dt class="deftypefn" id="index-ilu"><span class="category-def">: </span><span><code class="def-type"><var class="var">LUA</var> =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(<var class="var">A</var>)</code><a class="copiable-link" href="#index-ilu"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-ilu-1"><span class="category-def">: </span><span><code class="def-type"><var class="var">LUA</var> =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(<var class="var">A</var>, <var class="var">opts</var>)</code><a class="copiable-link" href="#index-ilu-1"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-ilu-2"><span class="category-def">: </span><span><code class="def-type">[<var class="var">L</var>, <var class="var">U</var>] =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(&hellip;)</code><a class="copiable-link" href="#index-ilu-2"> &para;</a></span></dt>
<dt class="deftypefnx def-cmd-deftypefn" id="index-ilu-3"><span class="category-def">: </span><span><code class="def-type">[<var class="var">L</var>, <var class="var">U</var>, <var class="var">P</var>] =</code> <strong class="def-name">ilu</strong> <code class="def-code-arguments">(&hellip;)</code><a class="copiable-link" href="#index-ilu-3"> &para;</a></span></dt>
<dd>
<p>Compute the incomplete LU factorization of the sparse square matrix <var class="var">A</var>.
</p>
<p><code class="code">ilu</code> returns a unit lower triangular matrix <var class="var">L</var>, an upper
triangular matrix <var class="var">U</var>, and optionally a permutation matrix <var class="var">P</var>, such
that <code class="code"><var class="var">L</var>*<var class="var">U</var></code> approximates <code class="code"><var class="var">P</var>*<var class="var">A</var></code>.
</p>
<p>The factors given by this routine may be useful as preconditioners for a
system of linear equations being solved by iterative methods such as BICG
(BiConjugate Gradients) or GMRES (Generalized Minimum Residual Method).
</p>
<p>The factorization may be modified by passing options in a structure
<var class="var">opts</var>.  The option name is a field of the structure and the setting
is the value of field.  Names and specifiers are case sensitive.
</p>
<dl class="table">
<dt><code class="code">type</code></dt>
<dd><p>Type of factorization.
</p>
<dl class="table">
<dt><code class="code">&quot;nofill&quot;</code> (default)</dt>
<dd><p>ILU factorization with no fill-in (ILU(0)).
</p>
<p>Additional supported options: <code class="code">milu</code>.
</p>
</dd>
<dt><code class="code">&quot;crout&quot;</code></dt>
<dd><p>Crout version of ILU factorization (ILUC).
</p>
<p>Additional supported options: <code class="code">milu</code>, <code class="code">droptol</code>.
</p>
</dd>
<dt><code class="code">&quot;ilutp&quot;</code></dt>
<dd><p>ILU factorization with threshold and pivoting.
</p>
<p>Additional supported options: <code class="code">milu</code>, <code class="code">droptol</code>, <code class="code">udiag</code>,
<code class="code">thresh</code>.
</p></dd>
</dl>

</dd>
<dt><code class="code">droptol</code></dt>
<dd><p>A non-negative scalar specifying the drop tolerance for factorization.  The
default value is 0 which produces the complete LU factorization.
</p>
<p>Non-diagonal entries of <var class="var">U</var> are set to 0 unless
</p>
<p><code class="code">abs (<var class="var">U</var>(i,j)) &gt;= droptol * norm (<var class="var">A</var>(:,j))</code>.
</p>
<p>Non-diagonal entries of <var class="var">L</var> are set to 0 unless
</p>
<p><code class="code">abs (<var class="var">L</var>(i,j)) &gt;= droptol * norm (<var class="var">A</var>(:,j))/<var class="var">U</var>(j,j)</code>.
</p>
</dd>
<dt><code class="code">milu</code></dt>
<dd><p>Modified incomplete LU factorization:
</p>
<dl class="table">
<dt><code class="code">&quot;row&quot;</code></dt>
<dd><p>Row-sum modified incomplete LU factorization.
The factorization preserves row sums:
<code class="code"><var class="var">A</var> * e = <var class="var">L</var> * <var class="var">U</var> * e</code>, where e is a vector of ones.
</p>
</dd>
<dt><code class="code">&quot;col&quot;</code></dt>
<dd><p>Column-sum modified incomplete LU factorization.
The factorization preserves column sums:
<code class="code">e' * <var class="var">A</var> = e' * <var class="var">L</var> * <var class="var">U</var></code>.
</p>
</dd>
<dt><code class="code">&quot;off&quot;</code> (default)</dt>
<dd><p>Row and column sums are not necessarily preserved.
</p></dd>
</dl>

</dd>
<dt><code class="code">udiag</code></dt>
<dd><p>If true, any zeros on the diagonal of the upper triangular factor are
replaced by the local drop tolerance
<code class="code">droptol * norm (<var class="var">A</var>(:,j))/<var class="var">U</var>(j,j)</code>.  The default is false.
</p>
</dd>
<dt><code class="code">thresh</code></dt>
<dd><p>Pivot threshold for factorization.  It can range between 0 (diagonal
pivoting) and 1 (default), where the maximum magnitude entry in the column
is chosen to be the pivot.
</p></dd>
</dl>

<p>If <code class="code">ilu</code> is called with just one output, the returned matrix is
<code class="code"><var class="var">L</var> + <var class="var">U</var> - speye (size (<var class="var">A</var>))</code>, where <var class="var">L</var> is unit
lower triangular and <var class="var">U</var> is upper triangular.
</p>
<p>With two outputs, <code class="code">ilu</code> returns a unit lower triangular matrix <var class="var">L</var>
and an upper triangular matrix <var class="var">U</var>.  For <var class="var">opts</var>.type ==
<code class="code">&quot;ilutp&quot;</code>, one of the factors is permuted based on the value of
<var class="var">opts</var>.milu.  When <var class="var">opts</var>.milu == <code class="code">&quot;row&quot;</code>, <var class="var">U</var> is a
column permuted upper triangular factor.  Otherwise, <var class="var">L</var> is a
row-permuted unit lower triangular factor.
</p>
<p>If there are three named outputs and <var class="var">opts</var>.milu != <code class="code">&quot;row&quot;</code>,
<var class="var">P</var> is returned such that <var class="var">L</var> and <var class="var">U</var> are incomplete factors
of <code class="code"><var class="var">P</var>*<var class="var">A</var></code>.  When <var class="var">opts</var>.milu == <code class="code">&quot;row&quot;</code>, <var class="var">P</var>
is returned such that <var class="var">L</var> and <var class="var">U</var> are incomplete factors of
<code class="code"><var class="var">A</var>*<var class="var">P</var></code>.
</p>
<p>EXAMPLES
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">A = gallery (&quot;neumann&quot;, 1600) + speye (1600);
opts.type = &quot;nofill&quot;;
nnz (A)
ans = 7840

nnz (lu (A))
ans = 126478

nnz (ilu (A, opts))
ans = 7840
</pre></div></div>

<p>This shows that <var class="var">A</var> has 7,840 nonzeros, the complete LU factorization
has 126,478 nonzeros, and the incomplete LU factorization, with 0 level of
fill-in, has 7,840 nonzeros, the same amount as <var class="var">A</var>.  Taken from:
<a class="url" href="https://www.mathworks.com/help/matlab/ref/ilu.html">https://www.mathworks.com/help/matlab/ref/ilu.html</a>
</p>
<div class="example">
<div class="group"><pre class="example-preformatted">A = gallery (&quot;wathen&quot;, 10, 10);
b = sum (A, 2);
tol = 1e-8;
maxit = 50;
opts.type = &quot;crout&quot;;
opts.droptol = 1e-4;
[L, U] = ilu (A, opts);
x = bicg (A, b, tol, maxit, L, U);
norm (A * x - b, inf)
</pre></div></div>

<p>This example uses ILU as preconditioner for a random FEM-Matrix, which has a
large condition number.  Without <var class="var">L</var> and <var class="var">U</var> BICG would not
converge.
</p>

<p><strong class="strong">See also:</strong> <a class="ref" href="Matrix-Factorizations.html#XREFlu">lu</a>, <a class="ref" href="#XREFichol">ichol</a>, <a class="ref" href="Specialized-Solvers.html#XREFbicg">bicg</a>, <a class="ref" href="Specialized-Solvers.html#XREFgmres">gmres</a>.
</p></dd></dl>


</div>
<hr>
<div class="nav-panel">
<p>
Next: <a href="Real-Life-Example.html">Real Life Example using Sparse Matrices</a>, Previous: <a href="Sparse-Linear-Algebra.html">Linear Algebra on Sparse Matrices</a>, Up: <a href="Sparse-Matrices.html">Sparse Matrices</a> &nbsp; [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Concept-Index.html" title="Index" rel="index">Index</a>]</p>
</div>



</body>
</html>
